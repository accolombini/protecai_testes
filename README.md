# ðŸ›¡ï¸ PROTECAI_TESTES

Sistema completo para **extraÃ§Ã£o, normalizaÃ§Ã£o e armazenamento de parÃ¢metros de proteÃ§Ã£o elÃ©trica** a partir de relatÃ³rios PDF (MiCOM S1 Agile / Easergy Studio).

## ðŸŒŸ Funcionalidades

âœ… **ExtraÃ§Ã£o de PDFs**: LÃª configuraÃ§Ãµes de relÃ©s e extrai parÃ¢metros estruturados  
âœ… **NormalizaÃ§Ã£o de Dados**: Processa e limpa dados extraÃ­dos com cÃ³digos ANSI padronizados  
âœ… **Base PostgreSQL**: Armazena dados em estrutura normalizada para anÃ¡lises complexas  
âœ… **Docker Compose**: Ambiente completo com PostgreSQL 16 + Adminer para gestÃ£o visual  
âœ… **Scripts de ImportaÃ§Ã£o**: Automatiza inserÃ§Ã£o de dados na base normalizada  
âœ… **ValidaÃ§Ã£o de Dados**: VerificaÃ§Ãµes de integridade e relatÃ³rios de importaÃ§Ã£o  

---

## ðŸ“‚ Estrutura de diretÃ³rios

```
protecai_testes/
â”œâ”€ input_pdfs/         # PDFs originais (tela1.pdf, tela3.pdf)
â”œâ”€ outputs/
â”‚  â”œâ”€ excel/           # Arquivos .xlsx extraÃ­dos
â”‚  â”œâ”€ csv/             # Arquivos .csv extraÃ­dos  
â”‚  â”œâ”€ norm_csv/        # CSVs normalizados para importaÃ§Ã£o
â”‚  â”œâ”€ norm_excel/      # VersÃµes Excel dos dados normalizados
â”‚  â”œâ”€ atrib_limpos/    # Arquivos com valores/unidades separados
â”‚  â”œâ”€ doc/             # DocumentaÃ§Ã£o e cÃ³digos normalizados
â”‚  â””â”€ logs/            # Logs de execuÃ§Ã£o e importaÃ§Ã£o
â”œâ”€ docker/
â”‚  â””â”€ postgres/        # ConfiguraÃ§Ã£o Docker PostgreSQL + Adminer
â”‚     â”œâ”€ docker-compose.yaml
â”‚     â”œâ”€ initdb/       # Scripts de inicializaÃ§Ã£o do banco
â”‚     â””â”€ data/         # Dados persistentes PostgreSQL (ignorado pelo git)
â”œâ”€ docs/               # DocumentaÃ§Ã£o SQL e modelagem
â”œâ”€ src/
â”‚  â”œâ”€ app.py           # CLI principal: extraÃ§Ã£o de PDFs
â”‚  â”œâ”€ normalizador.py  # NormalizaÃ§Ã£o com cÃ³digos ANSI
â”‚  â”œâ”€ importar_dados_normalizado.py    # ImportaÃ§Ã£o para PostgreSQL
â”‚  â”œâ”€ importar_dados_postgresql.py     # ImportaÃ§Ã£o alternativa
â”‚  â”œâ”€ validar_dados_importacao.py      # ValidaÃ§Ã£o pÃ³s-importaÃ§Ã£o
â”‚  â”œâ”€ parsers/         # FunÃ§Ãµes de parsing PDF
â”‚  â””â”€ utils/           # UtilitÃ¡rios diversos
â”œâ”€ tests/              # Testes automatizados
â”œâ”€ README.md
â””â”€ requirements.txt
```

---

## ðŸ³ Docker + PostgreSQL (Recomendado)

### 0. ConfiguraÃ§Ã£o inicial (apenas primeira vez)

Certifique-se de que o arquivo `.env` existe em `docker/postgres/`:

```bash
# Verificar se o arquivo .env existe
ls docker/postgres/.env

# Se nÃ£o existir, criar com as configuraÃ§Ãµes padrÃ£o:
cat > docker/postgres/.env << 'EOF'
POSTGRES_USER=protecai
POSTGRES_PASSWORD=protecai
POSTGRES_DB=protecai_db
POSTGRES_PORT=5432
TZ=America/Sao_Paulo
EOF
```

### 1. Subir o ambiente Docker

```bash
# Navegar para o diretÃ³rio do Docker
cd docker/postgres

# Subir PostgreSQL + Adminer
docker compose up -d

# Verificar se os containers estÃ£o rodando
docker compose ps
```

**ServiÃ§os disponÃ­veis:**
- **PostgreSQL 16**: `localhost:5432`
- **Adminer** (interface web): http://localhost:8080

**Credenciais padrÃ£o:**
- **UsuÃ¡rio**: protecai
- **Senha**: protecai
- **Database**: protecai_db

### 2. Acessar o banco PostgreSQL

**Via psql (linha de comando):**
```bash
# Entrar no container PostgreSQL
docker exec -it postgres-protecai psql -U protecai -d protecai_db

# Ou diretamente do host (se tiver psql instalado)
# SerÃ¡ solicitada a senha: protecai
psql -h localhost -p 5432 -U protecai -d protecai_db
```

**Via Adminer (interface web):**
1. Acesse: http://localhost:8080
2. **âš ï¸ IMPORTANTE**: Mude "Sistema" de "MySQL" para "PostgreSQL"
3. **Sistema**: PostgreSQL (NÃƒO deixe MySQL!)
4. **Servidor**: postgres-protecai
5. **UsuÃ¡rio**: protecai
6. **Senha**: protecai
7. **Base de dados**: protecai_db

### 3. Gerenciar o ambiente Docker

```bash
# ðŸŸ¢ PARAR containers (mantÃ©m dados) - RECOMENDADO para pausa temporÃ¡ria
docker compose stop

# ðŸŸ¡ Reiniciar containers parados
docker compose start

# ðŸŸ  PARAR e REMOVER containers (mantÃ©m dados persistentes, mas remove containers)
docker compose down

# ðŸ”´ PARAR e REMOVER TUDO incluindo dados - âš ï¸ MUITO CUIDADO!
docker compose down -v
```

**ðŸ’¡ Dica**: Para pausar o trabalho, use sempre `docker compose stop`!

---

## âš™ï¸ Preparando o ambiente Python

### 1. Criar ambiente virtual
```bash
# Com virtualenvwrapper (macOS/Linux)
mkvirtualenv -p python3 protecai_testes
workon protecai_testes

# Ou com venv padrÃ£o
python3 -m venv venv

# Ativar ambiente virtual:
source venv/bin/activate     # macOS/Linux
# ou
venv\Scripts\activate        # Windows
```

### 2. Instalar dependÃªncias
```bash
pip install -r requirements.txt
```

---

## ðŸš€ Fluxo de trabalho completo

### NOVA ARQUITETURA UNIFICADA (2025-10-18)

ðŸ”¥ **IMPORTANTE**: O sistema agora usa arquitetura unificada onde **TODOS** os formatos sÃ£o convertidos para CSV padronizado antes do processamento.

```
inputs/{pdf,txt,xlsx,csv} â†’ [CONVERSOR UNIVERSAL] â†’ outputs/csv/ â†’ [PIPELINE ÃšNICO]
```

### 1. ConversÃ£o Universal â†’ CSV Padronizado

```bash
# Converter TODOS os formatos para CSV padronizado
python src/universal_format_converter.py

# Resultado: Todos os arquivos em formato (Code, Description, Value) em outputs/csv/
```

### 2. Pipeline Completo Unificado

```bash
# Pipeline completo: conversÃ£o + normalizaÃ§Ã£o + importaÃ§Ã£o
python src/pipeline_completo.py

# Apenas conversÃ£o (para testar)
python src/pipeline_completo.py --only-extract

# Pular normalizaÃ§Ã£o
python src/pipeline_completo.py --skip-normalization
```

### 3. NormalizaÃ§Ã£o ANSI (AutomÃ¡tica no Pipeline)

```bash
# JÃ¡ incluÃ­da no pipeline completo, mas pode ser executada separadamente:
python src/normalizador.py

# Gera arquivos em outputs/norm_csv/ e outputs/norm_excel/
```

### 4. ImportaÃ§Ã£o para PostgreSQL (AutomÃ¡tica no Pipeline)

**Importante**: Certifique-se que o Docker estÃ¡ rodando primeiro!

```bash
# JÃ¡ incluÃ­da no pipeline completo, mas pode ser executada separadamente:
python src/importar_dados_normalizado.py

# Verifica log de importaÃ§Ã£o
cat outputs/logs/relatorio_importacao.json
```

### âœ¨ Vantagens da Arquitetura Unificada

ðŸŽ¯ **ConsistÃªncia**: Todos os formatos seguem o mesmo pipeline apÃ³s conversÃ£o
ðŸ”§ **ManutenÃ§Ã£o**: Apenas um fluxo de processamento para manter
ðŸ“Š **Comparabilidade**: Dados padronizados facilitam anÃ¡lise comparativa
ðŸš€ **Performance**: Menos duplicaÃ§Ã£o de cÃ³digo e lÃ³gica
ðŸ›¡ï¸ **Confiabilidade**: Reduz pontos de falha no sistema

### ðŸ“ Estrutura de DiretÃ³rios Atualizada

```
inputs/
â”œâ”€â”€ pdf/          # PDFs dos relÃ©s (MiCOM, Easergy, etc.)
â”œâ”€â”€ txt/          # Arquivos texto estruturados
â”œâ”€â”€ xlsx/         # Planilhas Excel/LibreOffice
â”œâ”€â”€ csv/          # CSVs de outras fontes
â””â”€â”€ registry/     # Controle de arquivos processados

outputs/
â”œâ”€â”€ csv/          # ðŸŽ¯ CSV padronizado (Code, Description, Value)
â”œâ”€â”€ atrib_limpos/ # Dados limpos para normalizaÃ§Ã£o
â”œâ”€â”€ norm_csv/     # Dados normalizados (CSV)
â”œâ”€â”€ norm_excel/   # Dados normalizados (Excel)
â””â”€â”€ logs/         # RelatÃ³rios de processamento
```

### 5. Validar importaÃ§Ã£o

```bash
# Executar validaÃ§Ãµes pÃ³s-importaÃ§Ã£o
python src/validar_dados_importacao.py
```

---

## ðŸ“Š Explorando os dados no PostgreSQL

### Estrutura das tabelas

```sql
-- Verificar estrutura do schema
\dt protec_ai.*

-- Tabelas principais:
-- â€¢ fabricantes (6 registros: Schneider, ABB, GE, etc.)
-- â€¢ tipos_token (11 tipos: ANSI, IEEE, IEC, etc.)  
-- â€¢ arquivos (arquivos CSV processados)
-- â€¢ campos_originais (cÃ³digos e descriÃ§Ãµes originais)
-- â€¢ valores_originais (valores extraÃ­dos dos PDFs)
-- â€¢ tokens_valores (tokens normalizados com confianÃ§a)
```

### Consultas Ãºteis

```sql
-- Ver todos os fabricantes
SELECT * FROM protec_ai.fabricantes;

-- Dados completos (via view)
SELECT * FROM protec_ai.vw_dados_completos LIMIT 10;

-- CÃ³digos ANSI encontrados
SELECT * FROM protec_ai.vw_codigos_ansi;

-- Campos por fabricante
SELECT * FROM protec_ai.vw_campos_por_fabricante;

-- EstatÃ­sticas de importaÃ§Ã£o
SELECT 
    COUNT(*) as total_campos,
    COUNT(DISTINCT arquivo_id) as arquivos_processados
FROM protec_ai.campos_originais;
```

### Views disponÃ­veis

1. **`vw_dados_completos`**: VisÃ£o consolidada de todos os dados
2. **`vw_codigos_ansi`**: Apenas registros com cÃ³digos ANSI vÃ¡lidos  
3. **`vw_campos_por_fabricante`**: Agrupamento por fabricante

---

## ðŸ”§ Scripts utilitÃ¡rios

### Limpeza de valores/unidades
```bash
# Separar valores numÃ©ricos das unidades
python -m src.utils.split_units

# SaÃ­da em outputs/atrib_limpos/ com sufixo _clean.xlsx
```

### GeraÃ§Ã£o de documentaÃ§Ã£o
```bash
# Gerar documentaÃ§Ã£o dos cÃ³digos normalizados  
python -m src.utils.generate_docx_documentation

# SaÃ­da em outputs/doc/
```

---

## ðŸ§ª Testes e validaÃ§Ã£o

```bash
# Executar testes automatizados
pytest tests/

# Verificar logs de importaÃ§Ã£o
ls -la outputs/logs/

# Validar dados no PostgreSQL
python src/validar_dados_importacao.py
```

---

## ðŸ“ Logs e relatÃ³rios

### Locais importantes:
- **`outputs/logs/relatorio_importacao.json`**: Status da Ãºltima importaÃ§Ã£o
- **`outputs/logs/importacao_normalizada.log`**: Log detalhado do processo
- **`outputs/doc/`**: DocumentaÃ§Ã£o gerada automaticamente

### Exemplo de relatÃ³rio de importaÃ§Ã£o:
```json
{
  "arquivos_processados": 2,
  "fabricantes_inseridos": 6,
  "tipos_token_inseridos": 11,
  "campos_inseridos": 486,
  "valores_inseridos": 332,
  "tokens_inseridos": 332,
  "erros": [],
  "duracao_segundos": 1.1
}
```

---

## ðŸ” Troubleshooting

### Docker nÃ£o sobe
```bash
# Verificar se as portas estÃ£o livres
lsof -i :5432  # PostgreSQL
lsof -i :8080  # Adminer

# Recriar containers
docker compose down
docker compose up -d --force-recreate

# Ou reiniciar serviÃ§os
docker compose restart
```

### Erro de conexÃ£o PostgreSQL
```bash
# Verificar se o container estÃ¡ rodando
docker compose ps

# Ver logs do PostgreSQL
docker compose logs postgres-protecai

# Testar conexÃ£o
docker exec -it postgres-protecai psql -U protecai -d protecai_db -c "SELECT version();"
```

### Erro na importaÃ§Ã£o
```bash
# Verificar log detalhado
cat outputs/logs/relatorio_importacao.json

# Verificar estrutura do banco
docker exec -it postgres-protecai psql -U protecai -d protecai_db -c "\dt protec_ai.*"
```

---

## ðŸš€ PrÃ³ximos passos

- **API REST**: Desenvolver API para consultar dados normalizados
- **Dashboard**: Interface web para visualizaÃ§Ã£o dos dados
- **ML Pipeline**: Algoritmos de anÃ¡lise de padrÃµes nos parÃ¢metros  
- **ExportaÃ§Ã£o avanÃ§ada**: RelatÃ³rios customizados em mÃºltiplos formatos
- **IntegraÃ§Ã£o CI/CD**: Automatizar testes e deployments

---

## ðŸ“„ LicenÃ§a

Este projeto Ã© destinado para uso interno da Petrobras no contexto de proteÃ§Ã£o elÃ©trica.