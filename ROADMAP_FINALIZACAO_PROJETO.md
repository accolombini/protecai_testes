# üó∫Ô∏è ROADMAP DE FINALIZA√á√ÉO DO PROJETO - ProtecAI
## Data: 06 de Novembro de 2025

---

## üéØ OBJETIVO FINAL

**Entregar sistema completo e funcional:**
- ‚úÖ Pipeline de extra√ß√£o autom√°tica (50 rel√©s ‚Üí 500 rel√©s)
- ‚úÖ Banco de dados atualizado e validado
- ‚úÖ Frontend integrado com upload e visualiza√ß√£o
- ‚úÖ Relat√≥rios funcionais (PDF, Excel, CSV)
- ‚úÖ Sistema pronto para produ√ß√£o

---

## üìã FASES DO PROJETO (ORDEM DE EXECU√á√ÉO)

---

### üî¥ **FASE 1: AUDITORIA E ATUALIZA√á√ÉO DO BANCO DE DADOS**
**Status:** üü° EM ANDAMENTO  
**Prioridade:** CR√çTICA  
**Tempo estimado:** 1-2 horas  
**Respons√°vel:** Pr√≥xima a√ß√£o

#### **Tarefa 1.1: Auditar Banco vs Pipeline** ‚è≥
**Status:** PENDENTE  
**Arquivo:** `scripts/audit_database_vs_pipeline.py`  
**Descri√ß√£o:** Comparar dados do banco com CSVs normalizados

**A√ß√µes:**
- [ ] Conectar ao PostgreSQL
- [ ] Contar par√¢metros no banco (relay_settings)
- [ ] Contar par√¢metros nos CSVs (outputs/norm_csv/)
- [ ] Comparar contagens por equipamento
- [ ] Identificar diverg√™ncias
- [ ] Gerar relat√≥rio JSON em `outputs/reports/database_audit.json`

**Queries SQL:**
```sql
-- Total no banco
SELECT COUNT(*) FROM protec_ai.relay_settings;

-- Distribui√ß√£o por equipamento
SELECT equipment_id, COUNT(*) as params 
FROM protec_ai.relay_settings 
GROUP BY equipment_id 
ORDER BY params DESC;

-- √öltima importa√ß√£o
SELECT MAX(created_at) FROM protec_ai.relay_settings;
```

**Output esperado:**
```json
{
  "database": {
    "total_params": 14314,
    "total_equipment": 50,
    "last_import": "2025-11-06T10:00:00"
  },
  "pipeline": {
    "total_params": XXXXX,
    "total_equipment": 50
  },
  "divergences": {
    "missing_params": XXXX,
    "extra_params": XXXX,
    "equipment_with_issues": [...]
  }
}
```

---

#### **Tarefa 1.2: Limpar Banco (se necess√°rio)** ‚è≥
**Status:** PENDENTE (depende de 1.1)  
**Script:** SQL manual

**A√ß√µes:**
- [ ] Backup do banco atual
- [ ] DELETE FROM protec_ai.relay_settings;
- [ ] Verificar integridade (foreign keys)
- [ ] Confirmar limpeza

**SQL:**
```sql
-- Backup (dump antes de limpar)
pg_dump -U protecai -d protecai_db -t protec_ai.relay_settings > backup_relay_settings_20251106.sql

-- Limpar
DELETE FROM protec_ai.relay_settings;

-- Verificar
SELECT COUNT(*) FROM protec_ai.relay_settings; -- Deve retornar 0
```

---

#### **Tarefa 1.3: Re-importar Dados Normalizados** ‚è≥
**Status:** PENDENTE (depende de 1.2)  
**Arquivo:** `scripts/reimport_normalized_data.py`  
**Descri√ß√£o:** Importar os 50 CSVs normalizados para o banco

**A√ß√µes:**
- [ ] Ler cada CSV de `outputs/norm_csv/`
- [ ] Mapear equipamento (via equipment_tag)
- [ ] Inserir em relay_settings
  - parameter_code ‚Üí Code
  - parameter_name ‚Üí Description
  - set_value ‚Üí Value
  - unit_of_measure ‚Üí unit
- [ ] Validar inser√ß√£o (count)
- [ ] Gerar log de importa√ß√£o

**Estrutura CSV ‚Üí Banco:**
```
CSV:                      BANCO:
Code         ‚Üí           parameter_code
Description  ‚Üí           parameter_name
Value        ‚Üí           set_value
unit         ‚Üí           unit_of_measure
```

**Output esperado:**
```
‚úÖ 50/50 CSVs importados
‚úÖ XXXXX par√¢metros inseridos
‚úÖ 0 erros
üìÑ Log: outputs/logs/reimport_20251106_HHMMSS.log
```

---

#### **Tarefa 1.4: Validar Importa√ß√£o** ‚è≥
**Status:** PENDENTE (depende de 1.3)  
**Script:** SQL de valida√ß√£o

**A√ß√µes:**
- [ ] Contar total de par√¢metros
- [ ] Verificar distribui√ß√£o por equipamento
- [ ] Validar campos obrigat√≥rios preenchidos
- [ ] Comparar com expectativa (outputs/norm_csv/)

**SQL de valida√ß√£o:**
```sql
-- Total importado
SELECT COUNT(*) as total FROM protec_ai.relay_settings;

-- Por equipamento
SELECT 
  re.equipment_tag,
  COUNT(rs.id) as params
FROM protec_ai.relay_settings rs
JOIN protec_ai.relay_equipment re ON rs.equipment_id = re.id
GROUP BY re.equipment_tag
ORDER BY params DESC;

-- Campos vazios (n√£o deveria ter)
SELECT COUNT(*) FROM protec_ai.relay_settings 
WHERE parameter_code IS NULL OR parameter_name IS NULL;
```

---

### üî¥ **FASE 2: CORRIGIR GERA√á√ÉO DE RELAT√ìRIOS**
**Status:** üî¥ N√ÉO INICIADO  
**Prioridade:** CR√çTICA  
**Tempo estimado:** 1-2 horas  
**Respons√°vel:** Ap√≥s conclus√£o Fase 1

#### **Tarefa 2.1: Testar Relat√≥rios Atuais** ‚è≥
**Status:** PENDENTE  
**Descri√ß√£o:** Validar endpoints de relat√≥rios

**A√ß√µes:**
- [ ] Iniciar backend (`uvicorn api.main:app`)
- [ ] Testar GET `/api/v1/reports/metadata`
- [ ] Testar POST `/api/v1/reports/preview`
- [ ] Testar GET `/api/v1/reports/export/pdf?equipment_id=1`
- [ ] Testar GET `/api/v1/reports/export/xlsx?equipment_id=1`
- [ ] Testar GET `/api/v1/reports/export/csv?equipment_id=1`
- [ ] Documentar erros encontrados

**Comandos de teste:**
```bash
# Metadata
curl http://localhost:8000/api/v1/reports/metadata

# Preview
curl -X POST http://localhost:8000/api/v1/reports/preview \
  -H "Content-Type: application/json" \
  -d '{"equipment_ids": [1]}'

# Export PDF
curl http://localhost:8000/api/v1/reports/export/pdf?equipment_id=1 \
  --output test_report.pdf

# Export Excel
curl http://localhost:8000/api/v1/reports/export/xlsx?equipment_id=1 \
  --output test_report.xlsx

# Export CSV
curl http://localhost:8000/api/v1/reports/export/csv?equipment_id=1 \
  --output test_report.csv
```

**Erros esperados:**
```
‚ùå Dados vazios no relat√≥rio
‚ùå Formata√ß√£o quebrada
‚ùå Erro 500 (query SQL inv√°lida)
‚ùå Headers incorretos
```

---

#### **Tarefa 2.2: Corrigir Queries de Relat√≥rios** ‚è≥
**Status:** PENDENTE (depende de 2.1)  
**Arquivo:** `api/services/report_service.py`  
**Descri√ß√£o:** Corrigir queries SQL para incluir dados normalizados

**A√ß√µes:**
- [ ] Revisar query atual
- [ ] Adicionar colunas: parameter_code, unit_of_measure
- [ ] Testar query manualmente no PostgreSQL
- [ ] Atualizar service
- [ ] Re-testar endpoints

**Query corrigida (exemplo):**
```python
# ANTES (possivelmente incorreta)
query = """
SELECT parameter_name, set_value 
FROM protec_ai.relay_settings 
WHERE equipment_id = %s
"""

# DEPOIS (corrigida)
query = """
SELECT 
  parameter_code,
  parameter_name,
  set_value,
  unit_of_measure,
  category
FROM protec_ai.relay_settings 
WHERE equipment_id = %s
ORDER BY parameter_code
"""
```

---

#### **Tarefa 2.3: Corrigir Formata√ß√£o de Relat√≥rios** ‚è≥
**Status:** PENDENTE (depende de 2.2)  
**Arquivos:** 
- `api/services/report_service.py` (gera√ß√£o)
- `api/routers/reports.py` (endpoints)

**A√ß√µes:**
- [ ] **PDF:** Validar formata√ß√£o (reportlab)
  - Headers com logo/t√≠tulo
  - Tabela de par√¢metros
  - Footer com data/p√°gina
- [ ] **Excel:** Validar formata√ß√£o (openpyxl)
  - Planilha com abas (por categoria?)
  - Headers em negrito
  - Auto-width de colunas
- [ ] **CSV:** Validar encoding (UTF-8)
  - Delimitador correto (;)
  - Quote fields

**Exemplo de melhoria PDF:**
```python
# Adicionar headers
pdf.setFont("Helvetica-Bold", 16)
pdf.drawString(100, 800, f"Relat√≥rio de Configura√ß√£o - {equipment_tag}")

# Tabela de par√¢metros
data = [["C√≥digo", "Descri√ß√£o", "Valor", "Unidade"]]
for param in params:
    data.append([
        param.parameter_code,
        param.parameter_name,
        param.set_value,
        param.unit_of_measure
    ])
```

---

#### **Tarefa 2.4: Testar Relat√≥rios Corrigidos** ‚è≥
**Status:** PENDENTE (depende de 2.3)

**A√ß√µes:**
- [ ] Re-executar testes de 2.1
- [ ] Validar conte√∫do dos arquivos gerados
- [ ] Verificar formata√ß√£o visual
- [ ] Confirmar dados corretos
- [ ] Testar com m√∫ltiplos equipamentos

**Crit√©rios de sucesso:**
```
‚úÖ PDF gerado com dados corretos
‚úÖ Excel gerado com formata√ß√£o adequada
‚úÖ CSV gerado com encoding UTF-8
‚úÖ Todos os campos preenchidos
‚úÖ Dados batem com banco
```

---

### üü° **FASE 3: INTEGRAR FRONTEND COM PIPELINE**
**Status:** üî¥ N√ÉO INICIADO  
**Prioridade:** IMPORTANTE  
**Tempo estimado:** 2-3 horas  
**Respons√°vel:** Ap√≥s conclus√£o Fase 2

#### **Tarefa 3.1: Criar Upload de Rel√©s no Frontend** ‚è≥
**Status:** PENDENTE  
**Arquivo:** `frontend/protecai-frontend/src/components/RelayUpload.tsx`  
**Descri√ß√£o:** Componente React para upload de PDF/S40

**A√ß√µes:**
- [ ] Criar componente RelayUpload.tsx
- [ ] Input type="file" (aceitar .pdf, .S40, .s40)
- [ ] Bot√£o "Processar Rel√©"
- [ ] Loading state durante processamento
- [ ] Exibir resultado (par√¢metros extra√≠dos)
- [ ] Mensagens de erro apropriadas

**Estrutura do componente:**
```typescript
interface RelayUploadProps {}

const RelayUpload: React.FC<RelayUploadProps> = () => {
  const [file, setFile] = useState<File | null>(null);
  const [loading, setLoading] = useState(false);
  const [result, setResult] = useState<ProcessResult | null>(null);

  const handleUpload = async () => {
    // POST /api/relays/process
  };

  return (
    <div>
      <input type="file" accept=".pdf,.S40,.s40" onChange={...} />
      <button onClick={handleUpload}>Processar Rel√©</button>
      {loading && <Spinner />}
      {result && <ResultTable data={result} />}
    </div>
  );
};
```

---

#### **Tarefa 3.2: Criar Endpoint de Processamento** ‚è≥
**Status:** PENDENTE  
**Arquivo:** `api/routers/relays.py`  
**Descri√ß√£o:** Endpoint POST /api/relays/process

**A√ß√µes:**
- [ ] Criar rota POST /relays/process
- [ ] Receber arquivo (multipart/form-data)
- [ ] Salvar em inputs/pdf/ ou inputs/txt/
- [ ] Executar CompletePipelineProcessor
- [ ] Importar dados para banco
- [ ] Retornar resumo JSON

**Estrutura do endpoint:**
```python
@router.post("/process")
async def process_relay_file(
    file: UploadFile = File(...),
    db: Session = Depends(get_db)
):
    """
    Processa arquivo de rel√© e importa para banco
    
    Returns:
        {
          "status": "success",
          "equipment_tag": "REL-P220-XXX",
          "params_extracted": 150,
          "params_imported": 150,
          "output_files": {
            "csv": "outputs/csv/XXX.csv",
            "excel": "outputs/excel/XXX.xlsx",
            "norm_csv": "outputs/norm_csv/XXX.csv",
            "norm_excel": "outputs/norm_excel/XXX.xlsx"
          }
        }
    """
    # 1. Salvar arquivo
    # 2. Processar pipeline
    # 3. Importar para banco
    # 4. Retornar resumo
```

---

#### **Tarefa 3.3: Criar Visualiza√ß√£o de Dados Normalizados** ‚è≥
**Status:** PENDENTE  
**Arquivo:** `frontend/protecai-frontend/src/components/RelayNormalizedView.tsx`  
**Descri√ß√£o:** Tabela com dados normalizados

**A√ß√µes:**
- [ ] Criar componente RelayNormalizedView.tsx
- [ ] Tabela com colunas: Code, Description, Value, Unit, Category
- [ ] Filtros por categoria
- [ ] Ordena√ß√£o por c√≥digo
- [ ] Pagina√ß√£o
- [ ] Bot√µes de export (PDF/Excel/CSV)

**Estrutura:**
```typescript
interface NormalizedData {
  code: string;
  description: string;
  value: string;
  unit: string;
  category: string;
}

const RelayNormalizedView: React.FC<{equipmentId: number}> = ({equipmentId}) => {
  const [data, setData] = useState<NormalizedData[]>([]);
  const [filter, setFilter] = useState<string>("all");

  // Fetch data from /api/relays/{equipmentId}/settings

  return (
    <div>
      <FilterBar onChange={setFilter} />
      <Table data={filteredData} columns={columns} />
      <ExportButtons equipmentId={equipmentId} />
    </div>
  );
};
```

---

#### **Tarefa 3.4: Integrar com Menu Principal** ‚è≥
**Status:** PENDENTE  
**Descri√ß√£o:** Adicionar links no menu

**A√ß√µes:**
- [ ] Adicionar menu "Upload de Rel√©"
- [ ] Adicionar menu "Visualizar Dados Normalizados"
- [ ] Atualizar rotas no React Router

---

### üü¢ **FASE 4: TESTES E VALIDA√á√ÉO FINAL**
**Status:** üî¥ N√ÉO INICIADO  
**Prioridade:** ESSENCIAL  
**Tempo estimado:** 1 hora  
**Respons√°vel:** Ap√≥s conclus√£o Fase 3

#### **Tarefa 4.1: Testes End-to-End** ‚è≥
**Status:** PENDENTE  
**Descri√ß√£o:** Validar fluxo completo

**A√ß√µes:**
- [ ] **Teste 1:** Upload de novo rel√© via frontend
  - Escolher arquivo PDF
  - Clicar "Processar"
  - Aguardar processamento
  - Verificar resultado exibido
- [ ] **Teste 2:** Dados no banco
  - Query: SELECT * FROM relay_settings WHERE equipment_tag = 'XXX'
  - Confirmar dados corretos
- [ ] **Teste 3:** Relat√≥rios
  - Gerar PDF do novo rel√©
  - Gerar Excel
  - Gerar CSV
  - Validar conte√∫do
- [ ] **Teste 4:** Visualiza√ß√£o
  - Abrir "Visualizar Dados Normalizados"
  - Filtrar por categoria
  - Exportar dados

**Crit√©rios de sucesso:**
```
‚úÖ Upload funciona sem erros
‚úÖ Pipeline processa automaticamente
‚úÖ Dados aparecem no banco
‚úÖ Relat√≥rios geram corretamente
‚úÖ Frontend exibe dados corretos
```

---

#### **Tarefa 4.2: Testes de Regress√£o** ‚è≥
**Status:** PENDENTE  
**Descri√ß√£o:** Garantir que n√£o quebramos nada

**A√ß√µes:**
- [ ] Testar 50 equipamentos existentes
- [ ] Confirmar que frontend carrega dados
- [ ] Confirmar que relat√≥rios antigos geram
- [ ] Confirmar que queries continuam funcionando

---

#### **Tarefa 4.3: Testes de Performance** ‚è≥
**Status:** PENDENTE (opcional)  
**Descri√ß√£o:** Validar performance

**A√ß√µes:**
- [ ] Processar arquivo grande (SEPAM 1131 params)
- [ ] Medir tempo de processamento
- [ ] Medir tempo de importa√ß√£o
- [ ] Validar mem√≥ria (n√£o deve ultrapassar)

---

### üü¢ **FASE 5: DOCUMENTA√á√ÉO E ENTREGA**
**Status:** üî¥ N√ÉO INICIADO  
**Prioridade:** FINAL  
**Tempo estimado:** 30 minutos  
**Respons√°vel:** Ap√≥s conclus√£o Fase 4

#### **Tarefa 5.1: Criar README de Outputs** ‚è≥
**Status:** PENDENTE  
**Arquivo:** `outputs/README.md`

**A√ß√µes:**
- [ ] Documentar estrutura de cada output
- [ ] Explicar formato de cada arquivo
- [ ] Dar exemplos de uso

---

#### **Tarefa 5.2: Backup Completo** ‚è≥
**Status:** PENDENTE

**A√ß√µes:**
- [ ] Criar tar.gz de outputs/
- [ ] Backup do banco (pg_dump)
- [ ] Salvar em local seguro

---

#### **Tarefa 5.3: Atualizar STATUS.md** ‚è≥
**Status:** PENDENTE

**A√ß√µes:**
- [ ] Consolidar todos os STATUS*.md
- [ ] Atualizar com conquistas finais
- [ ] Documentar pr√≥ximos passos (500 rel√©s)

---

## üìä M√âTRICAS DE SUCESSO

### **Banco de Dados:**
- [ ] Dados importados = Dados nos CSVs normalizados
- [ ] 50 equipamentos com par√¢metros completos
- [ ] 0 erros de integridade

### **Relat√≥rios:**
- [ ] PDF gerado com dados corretos
- [ ] Excel formatado adequadamente
- [ ] CSV com encoding UTF-8
- [ ] Tempo de gera√ß√£o < 5s

### **Frontend:**
- [ ] Upload de rel√©s funcional
- [ ] Pipeline executada automaticamente
- [ ] Dados exibidos corretamente
- [ ] Export PDF/Excel/CSV funcional

### **Sistema Completo:**
- [ ] 100% dos testes passando
- [ ] 0 erros em produ√ß√£o
- [ ] Documenta√ß√£o completa
- [ ] Backup realizado

---

## ‚ö†Ô∏è RISCOS E MITIGA√á√ïES

### **Risco 1: Banco muito grande ap√≥s re-importa√ß√£o**
**Mitiga√ß√£o:** Validar contagem antes, fazer backup

### **Risco 2: Relat√≥rios com performance ruim**
**Mitiga√ß√£o:** Adicionar pagina√ß√£o, √≠ndices no banco

### **Risco 3: Upload de arquivo muito grande**
**Mitiga√ß√£o:** Limitar tamanho (max 50MB), processar em background

---

## üéØ PR√ìXIMA A√á√ÉO IMEDIATA

**FASE 1 - Tarefa 1.1:** Criar e executar `scripts/audit_database_vs_pipeline.py`

**Comando:**
```bash
cd /Users/accol/Library/Mobile\ Documents/com~apple~CloudDocs/UNIVERSIDADES/UFF/PROJETOS/PETROBRAS/PETRO_ProtecAI/protecai_testes
workon protecai_testes
python scripts/audit_database_vs_pipeline.py
```

**Resultado esperado:**
- Relat√≥rio JSON em `outputs/reports/database_audit.json`
- Identifica√ß√£o de diverg√™ncias
- Decis√£o: Limpar e re-importar ou n√£o

---

## üìÖ TIMELINE ESTIMADO

| Fase | Tempo | Conclus√£o Esperada |
|------|-------|-------------------|
| Fase 1 | 1-2h | Hoje (06/11 - tarde) |
| Fase 2 | 1-2h | Hoje (06/11 - noite) ou Amanh√£ |
| Fase 3 | 2-3h | Amanh√£ (07/11) |
| Fase 4 | 1h | Amanh√£ (07/11) |
| Fase 5 | 30min | Amanh√£ (07/11) |

**Total:** 5.5 - 8.5 horas de trabalho

---

## ‚úÖ CHECKLIST DE CONTROLE

### Fase 1: Banco de Dados
- [ ] 1.1 Auditoria executada
- [ ] 1.2 Banco limpo (se necess√°rio)
- [ ] 1.3 Dados re-importados
- [ ] 1.4 Valida√ß√£o conclu√≠da

### Fase 2: Relat√≥rios
- [ ] 2.1 Testes realizados
- [ ] 2.2 Queries corrigidas
- [ ] 2.3 Formata√ß√£o corrigida
- [ ] 2.4 Re-testes aprovados

### Fase 3: Frontend
- [ ] 3.1 Upload criado
- [ ] 3.2 Endpoint criado
- [ ] 3.3 Visualiza√ß√£o criada
- [ ] 3.4 Menu atualizado

### Fase 4: Valida√ß√£o
- [ ] 4.1 E2E testado
- [ ] 4.2 Regress√£o testada
- [ ] 4.3 Performance validada

### Fase 5: Entrega
- [ ] 5.1 README criado
- [ ] 5.2 Backup realizado
- [ ] 5.3 STATUS atualizado

---

**√öltima atualiza√ß√£o:** 06/11/2025 - 15:00  
**Status geral:** FASE 1 EM ANDAMENTO  
**Pr√≥xima revis√£o:** Ap√≥s conclus√£o de cada fase
